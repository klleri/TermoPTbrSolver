{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbc2cc35",
   "metadata": {},
   "source": [
    "Portuguese word structure fundamentally relies on how vowels (V) and consonants (C) combine to create syllables. As the rhythmic unit of speech, the syllable almost always has a vowel as its core, the main sound. Understanding this vowel-consonant interaction is key to finding the perfect word in the game Termo (the Portuguese version of Wordle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85eacb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import unicodedata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f6e243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = 'palavras_5letras.txt' \n",
    "TARGET_LENGTH = 5                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efbbcd3",
   "metadata": {},
   "source": [
    "##### Removes accents from a character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2288d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_char(char):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', char)\n",
    "                   if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86bd884",
   "metadata": {},
   "source": [
    "##### Defining the vowels and consonants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e935bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_VOWELS = set('aeiou')\n",
    "ALPHABET_PT_FULL = set('abcdefghijklmnopqrstuvwxyzÃ§')\n",
    "CONSONANTS = {char for char in ALPHABET_PT_FULL if char not in BASE_VOWELS}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79e4542",
   "metadata": {},
   "source": [
    "##### Variables and Counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b33b8bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_distinct_vowels = 0\n",
    "words_with_max_vowels = []\n",
    "\n",
    "consonant_counter = Counter()\n",
    "\n",
    "total_words_analyzed = 0\n",
    "total_consonants_counted = 0\n",
    "error_message = None # Store error messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50c9765",
   "metadata": {},
   "source": [
    "##### Reads the word file, performs vowel and consonant analysis and updates global variables with the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d76d8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_words():\n",
    "\n",
    "    global max_distinct_vowels, words_with_max_vowels, consonant_counter\n",
    "    global total_words_analyzed, total_consonants_counted, error_message\n",
    "    \n",
    "    if not os.path.exists(FILENAME):\n",
    "        error_message = f\"Critical Error: The file '{FILENAME}' was not found in the current directory.\"\n",
    "        print(error_message)\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        with open(FILENAME, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                original_word = line.strip()\n",
    "\n",
    "                # Consider only non-empty words with the exact target length\n",
    "                if original_word and len(original_word) == TARGET_LENGTH:\n",
    "                    # Normalize the word: lowercase and remove accents\n",
    "                    normalized_word = \"\".join(normalize_char(c) for c in original_word.lower())\n",
    "\n",
    "                    # Additional validation: check if all normalized characters are valid letters\n",
    "                    if all(c in ALPHABET_PT_FULL for c in normalized_word) and len(normalized_word) == TARGET_LENGTH:\n",
    "                        total_words_analyzed += 1\n",
    "                        vowels_in_word = set()\n",
    "\n",
    "                        # Iterate over each normalized letter in the word\n",
    "                        for letter in normalized_word:\n",
    "                            # Vowel Analysis\n",
    "                            if letter in BASE_VOWELS:\n",
    "                                vowels_in_word.add(letter)\n",
    "                            # Consonant Analysis\n",
    "                            elif letter in CONSONANTS:\n",
    "                                consonant_counter[letter] += 1\n",
    "                                total_consonants_counted += 1\n",
    "\n",
    "                        # Update Distinct Vowel Analysis Results\n",
    "                        num_distinct_vowels = len(vowels_in_word)\n",
    "                        if num_distinct_vowels > max_distinct_vowels:\n",
    "                            max_distinct_vowels = num_distinct_vowels\n",
    "                            words_with_max_vowels = [original_word]\n",
    "                        elif num_distinct_vowels == max_distinct_vowels:\n",
    "                            words_with_max_vowels.append(original_word)\n",
    "\n",
    "        print(f\"Analysis complete. {total_words_analyzed} valid {TARGET_LENGTH}-letter words were processed.\")\n",
    "        return True \n",
    "\n",
    "    except FileNotFoundError:\n",
    "        error_message = f\"Critical Error: The file '{FILENAME}' was not found.\"\n",
    "        print(error_message)\n",
    "        return False \n",
    "    except Exception as e:\n",
    "        error_message = f\"An unexpected error occurred during file processing: {e}\"\n",
    "        print(error_message)\n",
    "        return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03f5111d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete. 19082 valid 5-letter words were processed.\n"
     ]
    }
   ],
   "source": [
    "analysis_completed = analyze_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0ea57e",
   "metadata": {},
   "source": [
    "##### Insights\n",
    "\n",
    "Now, let's move on to finding the best starting words for the game. The goal is to identify words that maximize our chances of guessing letters correctly on the first try.\n",
    "\n",
    "To do this, we'll combine some insights. We're looking for words that not only contain a good number of distinct vowels (to test which vowels are present) but also include some of the most frequently occurring consonants we identified earlier. This strategy aims to gather the most information possible with the initial guess."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b2990a",
   "metadata": {},
   "source": [
    "##### Prints the results of the distinct vowel analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da11a353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_vowel_results():\n",
    "    \n",
    "    if error_message and not total_words_analyzed: # Show error only if analysis didn't even start\n",
    "        print(f\"Cannot display results due to a critical error: {error_message}\")\n",
    "    elif total_words_analyzed == 0:\n",
    "        print(f\"No valid {TARGET_LENGTH}-letter words were found or analyzed in the file '{FILENAME}'.\")\n",
    "    else:\n",
    "        print(f\"Total {TARGET_LENGTH}-letter words analyzed: {total_words_analyzed}\")\n",
    "        print(\"-\" * 40)\n",
    "        if words_with_max_vowels:\n",
    "            print(f\"Highest number of distinct vowels found: {max_distinct_vowels}\")\n",
    "            print(f\"Words with {max_distinct_vowels} distinct vowels ({len(words_with_max_vowels)} found):\")\n",
    "            # Print words, 15 per line\n",
    "            for i in range(0, len(words_with_max_vowels), 15):\n",
    "                print(\", \".join(words_with_max_vowels[i:i+15]))\n",
    "        else:\n",
    "            print(\"No words containing vowels were found.\")\n",
    "        if error_message:\n",
    "             print(f\"\\nNote: An error occurred during processing: {error_message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfc92a36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 5-letter words analyzed: 19082\n",
      "----------------------------------------\n",
      "Highest number of distinct vowels found: 4\n",
      "Words with 4 distinct vowels (132 found):\n",
      "aboei, aboie, acoei, acuei, adioe, adiou, adoei, aduei, afeio, afeou, afiou, aguei, aiemo, aigue, aioes\n",
      "airou, aiues, aiune, aiuno, ajoie, aleio, aleou, aliou, aluei, aluio, ameio, ameou, amoie, amuei, aneio\n",
      "aneou, aoqui, apeio, apeou, apoie, apuei, apuie, aqueo, areio, areou, ariou, ateio, ateou, atoei, atuei\n",
      "audio, aueti, aueto, aunei, aurei, aureo, ausio, aveio, aviou, avoei, azoei, baiou, caiou, caiue, cuiao\n",
      "ecoai, eguai, eicou, eimou, eivao, eivou, eixou, eluia, eolia, equio, euria, eurio, faiou, feiao, gaiou\n",
      "guaie, guaio, guiao, iameu, iaque, iauos, iaupe, iauvo, ideou, iogue, iolau, iuane, iucea, lauie, maeio\n",
      "maiou, meiao, mueia, odeia, ofaie, oguei, oigue, oleai, oleia, opaie, oquea, oquei, oquie, oreai, oreia\n",
      "ouari, ougai, ourai, ourei, ousai, ousei, ousia, ousie, outai, outei, ouvia, oviua, ozeai, ozeia, queia\n",
      "raiou, uaios, uamoi, uiape, uleia, uniao, unioa, upiao, ureia, vaiou, veiou, zoeia\n"
     ]
    }
   ],
   "source": [
    "display_vowel_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa913bc",
   "metadata": {},
   "source": [
    "##### Prints the results of the consonant frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e505d230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_consonant_results():\n",
    "\n",
    "    if error_message and not total_words_analyzed: \n",
    "        print(f\"Cannot display results due to a critical error: {error_message}\")\n",
    "    elif total_words_analyzed == 0:\n",
    "         print(f\"No valid {TARGET_LENGTH}-letter words were found or analyzed in the file '{FILENAME}'.\")\n",
    "    else:\n",
    "        print(f\"Total {TARGET_LENGTH}-letter words analyzed: {total_words_analyzed}\")\n",
    "        print(f\"Total consonants counted: {total_consonants_counted}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        if consonant_counter:\n",
    "            top_10_consonants = consonant_counter.most_common(10)\n",
    "            print(\"The 10 most frequent consonants are:\")\n",
    "            print(f\"{'Rank':<6} {'Consonant':<12} {'Frequency':<12}\")\n",
    "            print(\"-\" * 40)\n",
    "            for rank, (consonant, frequency) in enumerate(top_10_consonants, 1):\n",
    "                print(f\"{rank:<6} {consonant:<12} {frequency:<12}\")\n",
    "        elif total_consonants_counted == 0 and total_words_analyzed > 0:\n",
    "             print(\"No consonants were found in the analyzed words.\")\n",
    "        else:\n",
    "             print(\"No consonants were counted.\")\n",
    "        if error_message: # Display non-critical errors\n",
    "             print(f\"\\nNote: An error occurred during processing: {error_message}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdd4c3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 5-letter words analyzed: 19082\n",
      "Total consonants counted: 48302\n",
      "----------------------------------------\n",
      "The 10 most frequent consonants are:\n",
      "Rank   Consonant    Frequency   \n",
      "----------------------------------------\n",
      "1      s            6375        \n",
      "2      r            5981        \n",
      "3      m            4282        \n",
      "4      l            4028        \n",
      "5      c            3886        \n",
      "6      n            3465        \n",
      "7      t            3432        \n",
      "8      p            2498        \n",
      "9      b            2471        \n",
      "10     d            2408        \n"
     ]
    }
   ],
   "source": [
    "display_consonant_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8b59a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
